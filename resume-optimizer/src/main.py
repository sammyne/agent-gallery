import streamlit as st
import os
from llama_index.core import SimpleDirectoryReader, Settings, VectorStoreIndex

from dotenv import load_dotenv
import tempfile
import shutil
import base64
# from PyPDF2 import PdfReader

import model

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


def run_rag_completion(
    documents,
    query_text: str,
    job_title: str,
    job_description: str,
    embedding_model: str,
    generative_model: str,
) -> str:
    """Run RAG completion using Nebius models for resume optimization."""
    llm = model.must_new_openai_like(generative_model)
    embed_model = model.must_new_openai_like_embedding(embedding_model)

    Settings.llm = llm
    Settings.embed_model = embed_model

    # Step 1: Analyze the resume
    analysis_prompt = f"""
    è¯¦ç»†åˆ†æè¿™ä»½ç®€å†ã€‚é‡ç‚¹å…³æ³¨ï¼š
    1. å…³é”®æŠ€èƒ½å’Œä¸“ä¸šèƒ½åŠ›
    2. å·¥ä½œç»éªŒå’Œæˆå°±
    3. æ•™è‚²èƒŒæ™¯å’Œè®¤è¯
    4. é‡è¦é¡¹ç›®æˆ–æˆå°±
    5. èŒä¸šå‘å±•è½¨è¿¹å’Œç©ºç¼ºæœŸ
    
    è¯·ä»¥è¦ç‚¹å½¢å¼æä¾›ç®€æ´çš„åˆ†æã€‚
    """

    index = VectorStoreIndex.from_documents(documents)
    resume_analysis = index.as_query_engine(similarity_top_k=5).query(
        analysis_prompt
    )

    # Step 2: Generate optimization suggestions
    optimization_prompt = f"""
    åŸºäºç®€å†åˆ†æå’ŒèŒä½è¦æ±‚ï¼Œæä¾›å…·ä½“ã€å¯æ“ä½œçš„æ”¹è¿›å»ºè®®ã€‚
    
    ç®€å†åˆ†æï¼š
    {resume_analysis}
    
    èŒä½åç§°ï¼š{job_title}
    èŒä½æè¿°ï¼š{job_description}
    
    ä¼˜åŒ–è¯·æ±‚ï¼š{query_text}
    
    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æä¾›ç›´æ¥ã€ç»“æ„åŒ–çš„å›åº”ï¼š

    ## ä¸»è¦å‘ç°
    â€¢ [2-3ä¸ªè¦ç‚¹ï¼Œçªå‡ºä¸»è¦åŒ¹é…åº¦å’Œå·®è·]

    ## å…·ä½“æ”¹è¿›
    â€¢ [3-5ä¸ªè¦ç‚¹ï¼Œæä¾›å…·ä½“å»ºè®®]
    â€¢ æ¯ä¸ªè¦ç‚¹åº”ä»¥å¼ºæœ‰åŠ›çš„åŠ¨ä½œåŠ¨è¯å¼€å¤´
    â€¢ å°½å¯èƒ½åŒ…å«å…·ä½“ç¤ºä¾‹

    ## è¡ŒåŠ¨é¡¹ç›®
    â€¢ [2-3ä¸ªå…·ä½“çš„ã€ç«‹å³å¯ä»¥æ‰§è¡Œçš„æ­¥éª¤]
    â€¢ æ¯ä¸ªé¡¹ç›®åº”æ¸…æ™°æ˜ç¡®ä¸”å¯å®æ–½

    ä¿æŒæ‰€æœ‰è¦ç‚¹ç®€æ´ä¸”å¯æ“ä½œã€‚ä¸è¦åŒ…å«ä»»ä½•æ€è€ƒè¿‡ç¨‹æˆ–åˆ†æã€‚
    """

    optimization_suggestions = index.as_query_engine(similarity_top_k=5).query(
        optimization_prompt
    )

    return str(optimization_suggestions)


def display_pdf_preview(pdf_file):
    """Display PDF preview in the sidebar."""
    try:
        st.sidebar.subheader("Resume Preview")
        base64_pdf = base64.b64encode(pdf_file.getvalue()).decode("utf-8")
        pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="100%" height="500" type="application/pdf"></iframe>'
        st.sidebar.markdown(pdf_display, unsafe_allow_html=True)
        return True
    except Exception as e:
        st.sidebar.error(f"Error previewing PDF: {str(e)}")
        return False


def main():
    st.set_page_config(page_title="Resume Optimizer", layout="wide")

    # Initialize session states
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "docs_loaded" not in st.session_state:
        st.session_state.docs_loaded = False
    if "temp_dir" not in st.session_state:
        st.session_state.temp_dir = None
    if "current_pdf" not in st.session_state:
        st.session_state.current_pdf = None

    # Header
    st.title("ğŸ“ ç®€å†ä¼˜åŒ–å™¨")
    # st.caption("Powered by Nebius AI")

    # Sidebar for configuration
    with st.sidebar:
        # st.image("./Nebius.png", width=150)

        # Model selection
        generative_model = st.selectbox(
            "å¤§æ¨¡å‹", ["qwen3-max","qwen3-max-2025-09-23", "deepseek-v3.2-exp"], index=0
        )

        # å‘é‡åŒ–æ¨¡å‹é€‰æ‹©
        embedding_model = st.selectbox(
            "æ–‡æœ¬å‘é‡æ¨¡å‹", ["text-embedding-v4", "text-embedding-v2"], index=0
        )

        st.divider()

        st.subheader("ä¸Šä¼ ç®€å†")
        uploaded_file = st.file_uploader(
            "é€‰æ‹©ä½ çš„ç®€å†ï¼ˆPDFï¼‰", type="pdf", accept_multiple_files=False
        )

        # PDF ä¸Šä¼ å’Œå¤„ç†
        if uploaded_file is not None:
            if uploaded_file != st.session_state.current_pdf:
                st.session_state.current_pdf = uploaded_file
                try:
                    # if not os.getenv("NEBIUS_API_KEY"):
                    #     st.error("Missing Nebius API key")
                    #     st.stop()

                    # åˆ›å»ºå­˜å‚¨ PDF çš„ä¸´æ—¶ç›®å½•
                    if st.session_state.temp_dir:
                        shutil.rmtree(st.session_state.temp_dir)
                    st.session_state.temp_dir = tempfile.mkdtemp()

                    # å°†ä¸Šä¼ çš„ pdf ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
                    file_path = os.path.join(
                        st.session_state.temp_dir, uploaded_file.name
                    )
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())

                    with st.spinner("ç®€å†åŠ è½½ä¸­ ..."):
                        documents = SimpleDirectoryReader(
                            st.session_state.temp_dir
                        ).load_data()
                        st.session_state.docs_loaded = True
                        st.session_state.documents = documents
                        st.success("âœ“ ç®€å†åŠ è½½æˆåŠŸ")
                        display_pdf_preview(uploaded_file)
                except Exception as e:
                    st.error(f"Error: {str(e)}")

    # Main content area
    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("èŒä½ä¿¡æ¯")
        job_title = st.text_input("èŒä½åç§°")
        job_description = st.text_area("èŒä½æè¿°", height=200)

        st.subheader("ä¼˜åŒ–é€‰é¡¹")
        optimization_type = st.selectbox(
            "é€‰æ‹©ä¼˜åŒ–ç±»å‹",
            [
                # ATS å…¨ç§°ç”³è¯·äººè·Ÿè¸ªç³»ç»Ÿï¼ˆApplicant Tracking Systemï¼‰åœ¨ç­›é€‰ç®€å†æ—¶é‡ç‚¹å…³æ³¨çš„æŠ€èƒ½ã€ç»éªŒæˆ–èµ„æ ¼ç­‰æ ¸å¿ƒè¯æ±‡ã€‚
                "ATSå…³é”®è¯ä¼˜åŒ–å™¨",
                "ç»éªŒéƒ¨åˆ†å¢å¼º",
                "æŠ€èƒ½å±‚æ¬¡åˆ›å»ºå™¨",
                "ä¸“ä¸šæ‘˜è¦æ’°å†™å™¨",
                "æ•™è‚²ä¼˜åŒ–",
                "æŠ€æœ¯æŠ€èƒ½å±•ç¤º",
                "èŒä¸šç©ºæ¡£æœŸæ¶¦è‰²",
            ],
        )

        if st.button("ä¼˜åŒ–ç®€å†"):
            if not st.session_state.docs_loaded:
                st.error("è¯·å…ˆä¸Šä¼ ä½ çš„ç®€å†")
                st.stop()
            if not job_title or not job_description:
                st.error("è¯·æä¾›èŒä½åç§°å’ŒèŒä½æè¿°")
                st.stop()

            # ä¼˜åŒ–ç±»å‹å¯¹åº”çš„ç”Ÿæˆä¼˜åŒ–æç¤ºè¯
            prompts = {
                "ATSå…³é”®è¯ä¼˜åŒ–å™¨": "è¯†åˆ«å¹¶ä¼˜åŒ–ATSå…³é”®è¯ã€‚é‡ç‚¹å…³æ³¨èŒä½æè¿°ä¸­çš„ç²¾ç¡®åŒ¹é…å’Œè¯­ä¹‰å˜ä½“ã€‚",
                "ç»éªŒéƒ¨åˆ†å¢å¼º": "å¢å¼ºç»éªŒéƒ¨åˆ†ä»¥ç¬¦åˆèŒä½è¦æ±‚ã€‚é‡ç‚¹å…³æ³¨å¯é‡åŒ–çš„æˆå°±ã€‚",
                "æŠ€èƒ½å±‚æ¬¡åˆ›å»º": "æ ¹æ®èŒä½è¦æ±‚ç»„ç»‡æŠ€èƒ½ã€‚è¯†åˆ«å·®è·å’Œå‘å±•æœºä¼šã€‚",
                "ä¸“ä¸šæ‘˜è¦æ’°å†™": "åˆ›å»ºé’ˆå¯¹æ€§çš„ä¸“ä¸šæ‘˜è¦ï¼Œçªå‡ºç›¸å…³ç»éªŒå’ŒæŠ€èƒ½ã€‚",
                "æ•™è‚²ä¼˜åŒ–": "ä¼˜åŒ–æ•™è‚²éƒ¨åˆ†ï¼Œå¼ºè°ƒä¸è¯¥èŒä½ç›¸å…³çš„èµ„æ ¼ã€‚",
                "æŠ€æœ¯æŠ€èƒ½å±•ç¤º": "æ ¹æ®èŒä½è¦æ±‚ç»„ç»‡æŠ€æœ¯æŠ€èƒ½ã€‚çªå‡ºå…³é”®èƒ½åŠ›ã€‚",
                "èŒä¸šç©ºæ¡£æœŸæ¶¦è‰²": "ä¸“ä¸šåœ°å¤„ç†èŒä¸šç©ºæ¡£æœŸã€‚å…³æ³¨æˆé•¿å’Œç›¸å…³ç»éªŒã€‚",
            }

            with st.spinner("åˆ†æç®€å†å¹¶ç”Ÿæˆå»ºè®®ä¸­..."):
                try:
                    response = run_rag_completion(
                        st.session_state.documents,
                        prompts[optimization_type],
                        job_title,
                        job_description,
                        embedding_model,
                        generative_model,
                    )
                    # Remove think tags from response
                    response = response.replace("<think>", "").replace("</think>", "")
                    st.session_state.messages.append(
                        {"role": "assistant", "content": response}
                    )
                except Exception as e:
                    st.error(f"Error: {str(e)}")

            st.divider()

    with col2:
        st.subheader("ä¼˜åŒ–ç»“æœ")
        for message in st.session_state.messages:
            st.markdown(message["content"])


if __name__ == "__main__":
    main()
